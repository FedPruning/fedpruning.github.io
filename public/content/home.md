---
title: FedPruning
subtitle: A Comprehensive Library and Benchmark for Efficient Federated Pruning
description: State-of-the-art federated pruning methods for distributed learning with model compression
cta:
  - text: Get Started
    link: https://honghuangs-organization.gitbook.io/fedpruning-documents
  - text: View on GitHub
    link: https://github.com/FedPruning/FedPruning
---

## About FedPruning

FedPruning is a comprehensive library designed for efficient federated pruning in distributed learning environments. It provides implementations of state-of-the-art federated pruning algorithms, standardized evaluation protocols, and extensible architectures for researchers and practitioners working on model compression in federated learning settings.

Our library addresses the critical challenge of deploying large-scale machine learning models on resource-constrained devices while maintaining privacy and model performance. By combining federated learning with neural network pruning, FedPruning enables efficient training and deployment of compressed models across heterogeneous devices.

## Key Features

### Comprehensive Methods
Includes classical and cutting-edge federated pruning algorithms including FedTiny, DepthFL, PruneFL, and more. Each method is carefully implemented and validated against published results.

### Easy to Use
Simple APIs and clear documentation for quick integration. Get started with just a few lines of code and seamlessly integrate with your existing federated learning pipeline.

### Benchmark Suite
Standardized evaluation protocols for fair comparison across different methods. Includes common datasets, metrics, and experimental settings for reproducible research.

### Extensible Design
Modular architecture for implementing custom pruning strategies. Easily extend base classes to implement your own algorithms and compare with existing methods.
