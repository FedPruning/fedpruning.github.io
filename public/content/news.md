---
title: News
description: Stay updated with our latest research publications, awards, presentations, and open-source releases.
---

## Sep 2026
**DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder** to appear at Arxiv. We introduce DC-VideoGen, a post-training acceleration framework for efficient video generation with a Deep Compression Video Autoencoder and a robust adaptation strategy AE-Adapt-V.

**Links**: [[DC-VideoGen]](#) [[Paper]](#) [[Code]](#)

---

## Aug 2026
**Neural Rendering at Scale: Photorealistic 3D Scene Reconstruction** accepted at SIGGRAPH 2026. We present a novel neural rendering pipeline that achieves photorealistic quality for large-scale outdoor scenes with real-time performance.

---

## Jul 2026
**EfficientDiffusion: Accelerating Text-to-Image Generation** to appear at CVPR 2026. A breakthrough in diffusion model acceleration achieving 10x speedup while maintaining image quality.

**Links**: [[Project Page]](#) [[Paper]](#) [[Demo]](#)

---

## May 2026
**MultiModal-LLM: Cross-Modal Understanding for Vision and Language** published in Nature Machine Intelligence. Our work demonstrates state-of-the-art performance on multiple vision-language benchmarks.

**Links**: [[Paper]](#) [[Code]](#)

---

## Mar 2026
**Invited Talk** at Stanford AI Lab on "The Future of Generative Models". Discussed recent advances in video generation and future research directions.

---

## Dec 2025
**Radial Attention: O(nlogn) Sparse Attention with Energy Decay for Long Video Generation** to appear at NeurIPS 2025. A O(nlogn) Sparse Attention Mask for Long Video Generation

**Links**: [[Radial Attention]](#) [[Paper]](#) [[Code]](#) [[Video]](#)

---

## Nov 2025
**Award Recognition**: Our paper "Temporal Coherence in Video Synthesis" received the Best Paper Award at ICCV 2025.

---

## Oct 2025
**SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation** appears at ICCV 2025. SANA-Sprint is a one-step distilled diffusion model enabling real-time generation; Deployable on laptop GPU; Top-notch GenEval & DPGBench results.

**Links**: [[SANA-Sprint]](#) [[Paper]](#) [[Code]](#) [[Video]](#)

---

## Sep 2025
**Open Source Release**: Released our video generation toolkit supporting multiple state-of-the-art models with unified API.

**Links**: [[GitHub]](#) [[Documentation]](#)

---

## Aug 2025
**Hierarchical Video Diffusion Models** accepted at ECCV 2025. We propose a hierarchical approach to video generation that improves temporal consistency and visual quality.

---

## Jun 2025
**Workshop Organization**: Co-organizing the Workshop on Generative Models for Video at CVPR 2025.

**Links**: [[Workshop Website]](#)

---

## Apr 2025
**ControlVideo: Controllable Video Synthesis with Spatial Guidance** published at TPAMI. Our method enables fine-grained control over video generation using various spatial conditions.

**Links**: [[Project]](#) [[Paper]](#) [[Code]](#) [[Demo]](#)

---

## Feb 2025
**Keynote Speaker** at AI Conference 2025. Presented "Scaling Video Generation: Challenges and Solutions".

---

## Jan 2025
**FastVideo-128: Real-Time High-Resolution Video Generation** to appear at AAAI 2025. Achieved real-time generation of 128-frame videos at 1024x1024 resolution.

**Links**: [[Paper]](#) [[Code]](#)

---

## Nov 2024
**Collaboration Announcement**: Started research collaboration with leading industry labs on next-generation video models.

---

## Sep 2024
**Tutorial Presentation** at ECCV 2024. Delivered a comprehensive tutorial on "Modern Approaches to Video Generation".

**Links**: [[Slides]](#) [[Video Recording]](#)

---

## Jul 2024
**3D-Aware Video Synthesis** accepted at SIGGRAPH 2024. Novel approach for generating videos with consistent 3D geometry.

**Links**: [[Project Page]](#) [[Paper]](#)

---

## May 2024
**Grant Award**: Received NSF CAREER Award for research on "Efficient and Controllable Video Generation".

---

## Mar 2024
**Motion-Guided Diffusion for Video Editing** appears at CVPR 2024. First work to enable precise motion control in diffusion-based video editing.

**Links**: [[Website]](#) [[Paper]](#) [[Code]](#) [[Colab Demo]](#)

---