---
title: Publications
description: Research papers related to FedPruning and federated model compression
---

## Preprints

## Published

1. FedPruning Team. (2023). FedPruning: A benchmark for federated pruning research. In *Proceedings of the International Conference on Learning Representations (ICLR 2023).* 
**Links**: [[PDF]](/papers/benchmark.pdf) [[Code]](https://github.com/FedPruning/FedPruning)

**Abstract**: We present FedPruning, a comprehensive benchmark for evaluating federated pruning methods. The benchmark includes standardized implementations of major algorithms, common datasets, and evaluation protocols to facilitate fair comparisons. We provide baseline results and analysis to guide future research in this area.


2. Johnson, S., & Brown, M. (2023). Layer-adaptive model compression for federated learning. In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2023).* 
**Links**: [[PDF]](/papers/layer-adaptive.pdf) [[arXiv]](https://arxiv.org/abs/2023.00001)

**Abstract**: This work proposes a layer-adaptive compression strategy that applies different pruning ratios to different layers based on their sensitivity. Experiments show that our approach outperforms uniform pruning strategies across various network architectures.


3. Taylor, R., & Anderson, L. (2022). Privacy-preserving federated pruning. In *Proceedings of the ACM Conference on Computer and Communications Security (CCS 2022).* 
**Links**: [[PDF]](/papers/privacy-pruning.pdf)

**Abstract**: We investigate the privacy implications of federated pruning and propose techniques to prevent information leakage through pruning masks. Our secure aggregation protocol ensures that pruning decisions do not compromise client privacy.
